{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "# from transformers import WavLMForSequenceClassification, WavLMProcessor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Loading and Preparation\n",
    "## 2.1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ravdess(data_dir):\n",
    "    emotion_labels = {\n",
    "        '01': 'neutral',\n",
    "        '02': 'calm',\n",
    "        '03': 'happy',\n",
    "        '04': 'sad',\n",
    "        '05': 'angry',\n",
    "        '06': 'fearful',\n",
    "        '07': 'disgust',\n",
    "        '08': 'surprised'\n",
    "    }\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                parts = file.split('-')\n",
    "                emotion = emotion_labels.get(parts[2])\n",
    "                file_list.append({'path': os.path.join(root, file), 'emotion': emotion})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_cremad(data_dir):\n",
    "    emotion_labels = {\n",
    "        'ANG': 'angry',\n",
    "        'DIS': 'disgust',\n",
    "        'FEA': 'fearful',\n",
    "        'HAP': 'happy',\n",
    "        'NEU': 'neutral',\n",
    "        'SAD': 'sad'\n",
    "    }\n",
    "    file_list = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            parts = file.split('_')\n",
    "            emotion = emotion_labels.get(parts[2])\n",
    "            if emotion:\n",
    "                file_list.append({'path': os.path.join(data_dir, file), 'emotion': emotion})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_tess(data_dir):\n",
    "    emotion_map = {\n",
    "        'angry': 'angry',\n",
    "        'disgust': 'disgust',\n",
    "        'fear': 'fearful',\n",
    "        'happy': 'happy',\n",
    "        'ps': 'surprised',  # Pleasant surprise\n",
    "        'sad': 'sad',\n",
    "        'neutral': 'neutral'\n",
    "    }\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                emotion = file.split('_')[2].split('.')[0]\n",
    "                emotion_label = emotion_map.get(emotion)\n",
    "                if emotion_label:\n",
    "                    file_list.append({'path': os.path.join(root, file), 'emotion': emotion_label})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_savee(data_dir):\n",
    "    emotion_map = {\n",
    "        'a': 'angry',\n",
    "        'd': 'disgust',\n",
    "        'f': 'fearful',\n",
    "        'h': 'happy',\n",
    "        'n': 'neutral',\n",
    "        'sa': 'sad',\n",
    "        'su': 'surprised'\n",
    "    }\n",
    "    file_list = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            emotion_code = file.split('_')[1][:2]\n",
    "            emotion_label = emotion_map.get(emotion_code)\n",
    "            if emotion_label:\n",
    "                file_list.append({'path': os.path.join(data_dir, file), 'emotion': emotion_label})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_df = load_data_ravdess('data/RAVDESS')\n",
    "cremad_df = load_data_cremad('data/CREMA-D')\n",
    "tess_df = load_data_tess('data/TESS')\n",
    "savee_df = load_data_savee('data/SAVEE')\n",
    "\n",
    "# Combine datasets\n",
    "data_df = pd.concat([ravdess_df, cremad_df, tess_df, savee_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize emotion labels\n",
    "emotion_list = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised', 'calm']\n",
    "\n",
    "# Handle any missing emotions in datasets\n",
    "data_df = data_df[data_df['emotion'].isin(emotion_list)]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(emotion_list)\n",
    "data_df['label'] = label_encoder.transform(data_df['emotion'])\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8261\n",
      "Validation samples: 1770\n",
      "Test samples: 1771\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(data_df, test_size=0.3, stratify=data_df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f'Training samples: {len(train_df)}')\n",
    "print(f'Validation samples: {len(val_df)}')\n",
    "print(f'Test samples: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Baseline Models\n",
    "## 3.1: Feature Extraction for Baseline Models\n",
    "### 3.1.1: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path, target_sr=16000):\n",
    "    y, sr = librosa.load(file_path, sr=None)  # Load with original sampling rate\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "    return y, sr\n",
    "\n",
    "def normalize_audio(y):\n",
    "    rms = np.sqrt(np.mean(y**2))\n",
    "    if rms > 0:\n",
    "        y_normalized = y / rms\n",
    "    else:\n",
    "        y_normalized = y\n",
    "    return y_normalized\n",
    "\n",
    "def augment_audio(y, sr):\n",
    "    augmented_data = []\n",
    "    \n",
    "    # Original\n",
    "    augmented_data.append(y)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.randn(len(y))\n",
    "    y_noise = y + 0.005 * noise\n",
    "    augmented_data.append(y_noise)\n",
    "    \n",
    "    # Time stretching\n",
    "    y_stretch = librosa.effects.time_stretch(y, rate=0.9)\n",
    "    augmented_data.append(y_stretch)\n",
    "    y_stretch = librosa.effects.time_stretch(y, rate=1.1)\n",
    "    augmented_data.append(y_stretch)\n",
    "    \n",
    "    # Pitch shifting\n",
    "    y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
    "    augmented_data.append(y_shift)\n",
    "    y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=-2)\n",
    "    augmented_data.append(y_shift)\n",
    "    \n",
    "    # Reverberation (simple simulation)\n",
    "    y_reverb = librosa.effects.preemphasis(y)\n",
    "    augmented_data.append(y_reverb)\n",
    "    \n",
    "    return augmented_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(file_path, n_mfcc=40, target_sr=16000, augment=False):\n",
    "    y, sr = load_audio(file_path, target_sr=target_sr)\n",
    "    y = normalize_audio(y)\n",
    "    \n",
    "    if augment:\n",
    "        augmented_audios = augment_audio(y, sr)\n",
    "    else:\n",
    "        augmented_audios = [y]\n",
    "    \n",
    "    features = []\n",
    "    for augmented_y in augmented_audios:\n",
    "        # Ensure consistent length by trimming or padding\n",
    "        max_length = target_sr * 3  # 3 seconds\n",
    "        # Trim or pad audio\n",
    "        if len(augmented_y) > max_length:\n",
    "            augmented_y = augmented_y[:max_length]\n",
    "        else:\n",
    "            augmented_y = np.pad(augmented_y, (0, max_length - len(augmented_y)), mode='constant')\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=augmented_y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs = np.mean(mfccs.T, axis=0)\n",
    "        \n",
    "        # Extract additional features if needed\n",
    "        chroma = librosa.feature.chroma_stft(y=augmented_y, sr=sr)\n",
    "        chroma = np.mean(chroma.T, axis=0)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=augmented_y, sr=sr)\n",
    "        spectral_contrast = np.mean(spectral_contrast.T, axis=0)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        feature_vector = np.concatenate([mfccs, chroma, spectral_contrast])\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3: Extract Features for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_df(df):\n",
    "    features = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Extracting features'):\n",
    "        feature = extract_features(row['path'], augment=True)\n",
    "        features.append(feature)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features\n",
    "X_train = extract_features_for_df(train_df)\n",
    "X_val = extract_features_for_df(val_df)\n",
    "X_test = extract_features_for_df(test_df)\n",
    "\n",
    "# Get labels\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "y_test = test_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "X_train = np.array(X_train).reshape(len(X_train), -1)\n",
    "X_val = np.array(X_val).reshape(len(X_val), -1)\n",
    "X_test = np.array(X_test).reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the feature arrays\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "\n",
    "# Print a sample of the feature arrays\n",
    "print('Sample features from X_train:')\n",
    "print(X_train[0])\n",
    "\n",
    "print('Sample features from X_val:')\n",
    "print(X_val[0])\n",
    "\n",
    "print('Sample features from X_test:')\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation data using the fitted scaler\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Transform the test data using the fitted scaler\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Train and Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "val_accuracy_lr = accuracy_score(y_val, y_val_pred_lr)\n",
    "val_f1_lr = f1_score(y_val, y_val_pred_lr, average='weighted')\n",
    "\n",
    "print(f'Logistic Regression - Validation Accuracy: {val_accuracy_lr:.4f}, F1 Score: {val_f1_lr:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "val_f1_rf = f1_score(y_val, y_val_pred_rf, average='weighted')\n",
    "\n",
    "print(f'Random Forest - Validation Accuracy: {val_accuracy_rf:.4f}, F1 Score: {val_f1_rf:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Select random samples\n",
    "num_samples = 5\n",
    "random_indices = random.sample(range(len(test_df)), num_samples)\n",
    "sample_df = test_df.iloc[random_indices]\n",
    "\n",
    "# Extract features for the selected samples\n",
    "sample_features = np.array([extract_features(row['path'])[0] for _, row in sample_df.iterrows()])\n",
    "sample_features = scaler.transform(sample_features)\n",
    "\n",
    "# Get true labels and predictions\n",
    "sample_labels = sample_df['label'].values\n",
    "sample_predictions_lr = lr_model.predict(sample_features)\n",
    "sample_predictions_rf = rf_model.predict(sample_features)\n",
    "\n",
    "# Display the samples\n",
    "for i, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Path: {row['path']}\")\n",
    "    print(f\"True Label: {label_encoder.inverse_transform([sample_labels[i]])[0]}\")\n",
    "    print(f\"Logistic Regression Prediction: {label_encoder.inverse_transform([sample_predictions_lr[i]])[0]}\")\n",
    "    print(f\"Random Forest Prediction: {label_encoder.inverse_transform([sample_predictions_rf[i]])[0]}\")\n",
    "    ipd.display(ipd.Audio(row['path']))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)\n",
    "test_f1_lr = f1_score(y_test, y_test_pred_lr, average='weighted')\n",
    "print(f'Logistic Regression - Test Accuracy: {test_accuracy_lr:.4f}, F1 Score: {test_f1_lr:.4f}')\n",
    "\n",
    "# Random Forest\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_f1_rf = f1_score(y_test, y_test_pred_rf, average='weighted')\n",
    "print(f'Random Forest - Test Accuracy: {test_accuracy_rf:.4f}, F1 Score: {test_f1_rf:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# Set model parameters\n",
    "model_name_or_path = \"facebook/wav2vec2-base\"\n",
    "label_list = label_encoder.classes_\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# Load configuration\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    label2id={label: i for i, label in enumerate(label_list)},\n",
    "    id2label={i: label for i, label in enumerate(label_list)},\n",
    "    finetuning_task=\"wav2vec2_clf\",\n",
    ")\n",
    "config.pooling_mode = \"mean\"  # Set pooling mode to \"mean\"\n",
    "\n",
    "# Load processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Initialize the Precessor and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train dataset (num_proc=4): 100%|██████████| 8261/8261 [00:54<00:00, 152.05 examples/s] \n",
      "Processing eval dataset (num_proc=4): 100%|██████████| 1770/1770 [00:21<00:00, 81.66 examples/s]  \n",
      "Processing test dataset (num_proc=4): 100%|██████████| 1771/1771 [00:20<00:00, 84.44 examples/s]  \n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to load and resample audio\n",
    "def speech_file_to_array_fn(path):\n",
    "    speech_array, sampling_rate = librosa.load(path)\n",
    "    speech = librosa.resample(speech_array, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
    "    return speech\n",
    "\n",
    "# Define a function to map labels\n",
    "def label_to_id(label, label_list):\n",
    "    return label_list.index(label) if label in label_list else -1\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    speech_list = [speech_file_to_array_fn(path) for path in examples['path']]\n",
    "    target_list = [label_to_id(label, label_list.tolist()) for label in examples['emotion']]\n",
    "    \n",
    "    result = processor(speech_list, sampling_rate=target_sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    result[\"labels\"] = torch.tensor(target_list)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Convert pandas dataframe to Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Apply preprocessing with tqdm progress bar\n",
    "train_dataset = train_dataset.map(preprocess_function, batch_size=100, batched=True, num_proc=4, desc='Processing train dataset')\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batch_size=100, batched=True, num_proc=4, desc='Processing eval dataset')\n",
    "test_dataset = test_dataset.map(preprocess_function, batch_size=100, batched=True, num_proc=4, desc='Processing test dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.wav2vec2.modeling_wav2vec2 import Wav2Vec2PreTrainedModel, Wav2Vec2Model\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define classification head\n",
    "class Wav2Vec2ClassificationHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "# Define the Wav2Vec2 model for speech classification\n",
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "\n",
    "    def merged_strategy(self, hidden_states, mode=\"mean\"):\n",
    "        if mode == \"mean\":\n",
    "            return torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            return torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            return torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pooling mode. Choose from ['mean', 'sum', 'max']\")\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        outputs = self.wav2vec2(input_values, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        pooled_output = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSpeechClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# Load the model\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path, config=config)\n",
    "model.freeze_feature_extractor()\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2_clf_output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "# Data collator to dynamically pad inputs\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=processor.feature_extractor,  # Replace `processor` with `processor.feature_extractor`\n",
    "    padding=True  # Default behavior is to pad to the longest sequence in the batch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize Trainer\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/467final/lib/python3.10/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/467final/lib/python3.10/site-packages/transformers/trainer.py:430\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/miniconda3/envs/467final/lib/python3.10/site-packages/transformers/trainer.py:4960\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4957\u001b[0m     args\u001b[38;5;241m.\u001b[39mupdate(accelerator_config)\n\u001b[1;32m   4959\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 4960\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "File \u001b[0;32m~/miniconda3/envs/467final/lib/python3.10/site-packages/accelerate/accelerator.py:485\u001b[0m, in \u001b[0;36mAccelerator.__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, deepspeed_plugins)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusa\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(\n\u001b[1;32m    483\u001b[0m     check_is_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    484\u001b[0m ):\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    486\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler\u001b[38;5;241m.\u001b[39mto_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m get_grad_scaler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define compute metrics function\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "test_metrics = predictions.metrics\n",
    "print(f\"Test Accuracy: {test_metrics['test_accuracy']:.4f}, F1 Score: {test_metrics['test_f1']:.4f}\")\n",
    "\n",
    "# To analyze specific predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = test_dataset[\"labels\"]\n",
    "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred, target_names=label_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_dataset = EmotionDataset(train_df, processor, augment=False)\n",
    "val_dataset = EmotionDataset(val_df, processor, augment=False)\n",
    "test_dataset = EmotionDataset(test_df, processor, augment=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "def collate_fn(batch):\n",
    "    input_values = torch.stack([item['input_values'].squeeze() for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'].squeeze() for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {'input_values': input_values, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "for batch in train_loader:\n",
    "    input_values = batch['input_values']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "    print(input_values.shape, attention_mask.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_values=input_values, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_values=input_values, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "467final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
