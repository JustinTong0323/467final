{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tongxinyuan/miniconda3/envs/467final/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "# from transformers import WavLMForSequenceClassification, WavLMProcessor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torchaudio\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoConfig, Wav2Vec2Processor, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from typing import Dict, Any, Union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Loading and Preparation\n",
    "## 2.1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ravdess(data_dir):\n",
    "    emotion_labels = {\n",
    "        '01': 'neutral',\n",
    "        '02': 'calm',\n",
    "        '03': 'happy',\n",
    "        '04': 'sad',\n",
    "        '05': 'angry',\n",
    "        '06': 'fearful',\n",
    "        '07': 'disgust',\n",
    "        '08': 'surprised'\n",
    "    }\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                parts = file.split('-')\n",
    "                emotion = emotion_labels.get(parts[2])\n",
    "                file_list.append({'file_path': os.path.join(root, file), 'emotion': emotion})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_cremad(data_dir):\n",
    "    emotion_labels = {\n",
    "        'ANG': 'angry',\n",
    "        'DIS': 'disgust',\n",
    "        'FEA': 'fearful',\n",
    "        'HAP': 'happy',\n",
    "        'NEU': 'neutral',\n",
    "        'SAD': 'sad'\n",
    "    }\n",
    "    file_list = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            parts = file.split('_')\n",
    "            emotion = emotion_labels.get(parts[2])\n",
    "            if emotion:\n",
    "                file_list.append({'file_path': os.path.join(data_dir, file), 'emotion': emotion})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_tess(data_dir):\n",
    "    emotion_map = {\n",
    "        'angry': 'angry',\n",
    "        'disgust': 'disgust',\n",
    "        'fear': 'fearful',\n",
    "        'happy': 'happy',\n",
    "        'ps': 'surprised',  # Pleasant surprise\n",
    "        'sad': 'sad',\n",
    "        'neutral': 'neutral'\n",
    "    }\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                emotion = file.split('_')[2].split('.')[0]\n",
    "                emotion_label = emotion_map.get(emotion)\n",
    "                if emotion_label:\n",
    "                    file_list.append({'file_path': os.path.join(root, file), 'emotion': emotion_label})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n",
    "def load_data_savee(data_dir):\n",
    "    emotion_map = {\n",
    "        'a': 'angry',\n",
    "        'd': 'disgust',\n",
    "        'f': 'fearful',\n",
    "        'h': 'happy',\n",
    "        'n': 'neutral',\n",
    "        'sa': 'sad',\n",
    "        'su': 'surprised'\n",
    "    }\n",
    "    file_list = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            emotion_code = file.split('_')[1][:2]\n",
    "            emotion_label = emotion_map.get(emotion_code)\n",
    "            if emotion_label:\n",
    "                file_list.append({'file_path': os.path.join(data_dir, file), 'emotion': emotion_label})\n",
    "    return pd.DataFrame(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_df = load_data_ravdess('data/RAVDESS')\n",
    "cremad_df = load_data_cremad('data/CREMA-D')\n",
    "tess_df = load_data_tess('data/TESS')\n",
    "savee_df = load_data_savee('data/SAVEE')\n",
    "\n",
    "# Combine datasets\n",
    "data_df = pd.concat([ravdess_df, cremad_df, tess_df, savee_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize emotion labels\n",
    "emotion_list = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised', 'calm']\n",
    "\n",
    "# Handle any missing emotions in datasets\n",
    "data_df = data_df[data_df['emotion'].isin(emotion_list)]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(emotion_list)\n",
    "data_df['label'] = label_encoder.transform(data_df['emotion'])\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data_df\n",
    "data_df.to_csv('data_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Actor_05/03-01-08-02-01-01-05.wav</td>\n",
       "      <td>surprised</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Actor_05/03-01-06-02-01-01-05.wav</td>\n",
       "      <td>fearful</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Actor_05/03-01-06-02-01-02-05.wav</td>\n",
       "      <td>fearful</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Actor_05/03-01-02-01-02-02-05.wav</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/RAVDESS/Actor_05/03-01-05-01-01-02-05.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        file_path    emotion  label\n",
       "0  data/RAVDESS/Actor_05/03-01-08-02-01-01-05.wav  surprised      7\n",
       "1  data/RAVDESS/Actor_05/03-01-06-02-01-01-05.wav    fearful      3\n",
       "2  data/RAVDESS/Actor_05/03-01-06-02-01-02-05.wav    fearful      3\n",
       "3  data/RAVDESS/Actor_05/03-01-02-01-02-02-05.wav       calm      1\n",
       "4  data/RAVDESS/Actor_05/03-01-05-01-01-02-05.wav      angry      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "angry        1863\n",
       "calm          192\n",
       "disgust      1863\n",
       "fearful      1863\n",
       "happy        1863\n",
       "neutral      1583\n",
       "sad          1923\n",
       "surprised     652\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by emotion\n",
    "emotion_counts = data_df['emotion'].value_counts().sort_index()\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8261\n",
      "Validation samples: 1770\n",
      "Test samples: 1771\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(data_df, test_size=0.3, stratify=data_df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f'Training samples: {len(train_df)}') \n",
    "print(f'Validation samples: {len(val_df)}')\n",
    "print(f'Test samples: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>data/CREMA-D/1051_MTI_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>data/CREMA-D/1036_IOM_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>data/CREMA-D/1069_ITH_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>data/CREMA-D/1039_IOM_FEA_XX.wav</td>\n",
       "      <td>fearful</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>data/RAVDESS/Actor_07/03-01-02-01-01-02-07.wav</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  emotion  label\n",
       "4834                data/CREMA-D/1051_MTI_ANG_XX.wav    angry      0\n",
       "5876                data/CREMA-D/1036_IOM_DIS_XX.wav  disgust      2\n",
       "4623                data/CREMA-D/1069_ITH_ANG_XX.wav    angry      0\n",
       "7472                data/CREMA-D/1039_IOM_FEA_XX.wav  fearful      3\n",
       "452   data/RAVDESS/Actor_07/03-01-02-01-01-02-07.wav     calm      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Baseline Models\n",
    "## 3.1: Feature Extraction for Baseline Models\n",
    "### 3.1.1: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path, target_sr=16000):\n",
    "    y, sr = librosa.load(file_path, sr=None)  # Load with original sampling rate\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "    return y, sr\n",
    "\n",
    "def normalize_audio(y):\n",
    "    rms = np.sqrt(np.mean(y**2))\n",
    "    if rms > 0:\n",
    "        y_normalized = y / rms\n",
    "    else:\n",
    "        y_normalized = y\n",
    "    return y_normalized\n",
    "\n",
    "def augment_audio(y, sr):\n",
    "    augmented_data = []\n",
    "    \n",
    "    # Original\n",
    "    augmented_data.append(y)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.randn(len(y))\n",
    "    y_noise = y + 0.005 * noise\n",
    "    augmented_data.append(y_noise)\n",
    "    \n",
    "    # Time stretching\n",
    "    y_stretch = librosa.effects.time_stretch(y, rate=0.9)\n",
    "    augmented_data.append(y_stretch)\n",
    "    y_stretch = librosa.effects.time_stretch(y, rate=1.1)\n",
    "    augmented_data.append(y_stretch)\n",
    "    \n",
    "    # Pitch shifting\n",
    "    y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
    "    augmented_data.append(y_shift)\n",
    "    y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=-2)\n",
    "    augmented_data.append(y_shift)\n",
    "    \n",
    "    # Reverberation (simple simulation)\n",
    "    y_reverb = librosa.effects.preemphasis(y)\n",
    "    augmented_data.append(y_reverb)\n",
    "    \n",
    "    return augmented_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(file_path, n_mfcc=40, target_sr=16000, augment=False):\n",
    "    y, sr = load_audio(file_path, target_sr=target_sr)\n",
    "    y = normalize_audio(y)\n",
    "    \n",
    "    if augment:\n",
    "        augmented_audios = augment_audio(y, sr)\n",
    "    else:\n",
    "        augmented_audios = [y]\n",
    "    \n",
    "    features = []\n",
    "    for augmented_y in augmented_audios:\n",
    "        # Ensure consistent length by trimming or padding\n",
    "        max_length = target_sr * 3  # 3 seconds\n",
    "        # Trim or pad audio\n",
    "        if len(augmented_y) > max_length:\n",
    "            augmented_y = augmented_y[:max_length]\n",
    "        else:\n",
    "            augmented_y = np.pad(augmented_y, (0, max_length - len(augmented_y)), mode='constant')\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=augmented_y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs = np.mean(mfccs.T, axis=0)\n",
    "        \n",
    "        # Extract additional features if needed\n",
    "        chroma = librosa.feature.chroma_stft(y=augmented_y, sr=sr)\n",
    "        chroma = np.mean(chroma.T, axis=0)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=augmented_y, sr=sr)\n",
    "        spectral_contrast = np.mean(spectral_contrast.T, axis=0)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        feature_vector = np.concatenate([mfccs, chroma, spectral_contrast])\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3: Extract Features for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_df(df):\n",
    "    features = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Extracting features'):\n",
    "        feature = extract_features(row['file_path'], augment=False)\n",
    "        features.append(feature)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features\n",
    "X_train = extract_features_for_df(train_df)\n",
    "X_val = extract_features_for_df(val_df)\n",
    "X_test = extract_features_for_df(test_df)\n",
    "\n",
    "# Get labels\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "y_test = test_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "X_train = np.array(X_train).reshape(len(X_train), -1)\n",
    "X_val = np.array(X_val).reshape(len(X_val), -1)\n",
    "X_test = np.array(X_test).reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the feature arrays\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "\n",
    "# Print a sample of the feature arrays\n",
    "print('Sample features from X_train:')\n",
    "print(X_train[0])\n",
    "\n",
    "print('Sample features from X_val:')\n",
    "print(X_val[0])\n",
    "\n",
    "print('Sample features from X_test:')\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation data using the fitted scaler\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Transform the test data using the fitted scaler\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Train and Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "val_accuracy_lr = accuracy_score(y_val, y_val_pred_lr)\n",
    "val_f1_lr = f1_score(y_val, y_val_pred_lr, average='weighted')\n",
    "\n",
    "print(f'Logistic Regression - Validation Accuracy: {val_accuracy_lr:.4f}, F1 Score: {val_f1_lr:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "val_f1_rf = f1_score(y_val, y_val_pred_rf, average='weighted')\n",
    "\n",
    "print(f'Random Forest - Validation Accuracy: {val_accuracy_rf:.4f}, F1 Score: {val_f1_rf:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Select random samples\n",
    "num_samples = 5\n",
    "random_indices = random.sample(range(len(test_df)), num_samples)\n",
    "sample_df = test_df.iloc[random_indices]\n",
    "\n",
    "# Extract features for the selected samples\n",
    "sample_features = np.array([extract_features(row['file_path'])[0] for _, row in sample_df.iterrows()])\n",
    "sample_features = scaler.transform(sample_features)\n",
    "\n",
    "# Get true labels and predictions\n",
    "sample_labels = sample_df['label'].values\n",
    "sample_predictions_lr = lr_model.predict(sample_features)\n",
    "sample_predictions_rf = rf_model.predict(sample_features)\n",
    "\n",
    "# Display the samples\n",
    "for i, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Path: {row['file_path']}\")\n",
    "    print(f\"True Label: {label_encoder.inverse_transform([sample_labels[i]])[0]}\")\n",
    "    print(f\"Logistic Regression Prediction: {label_encoder.inverse_transform([sample_predictions_lr[i]])[0]}\")\n",
    "    print(f\"Random Forest Prediction: {label_encoder.inverse_transform([sample_predictions_rf[i]])[0]}\")\n",
    "    ipd.display(ipd.Audio(row['file_path']))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)\n",
    "test_f1_lr = f1_score(y_test, y_test_pred_lr, average='weighted')\n",
    "print(f'Logistic Regression - Test Accuracy: {test_accuracy_lr:.4f}, F1 Score: {test_f1_lr:.4f}')\n",
    "\n",
    "# Random Forest\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_f1_rf = f1_score(y_test, y_test_pred_rf, average='weighted')\n",
    "print(f'Random Forest - Test Accuracy: {test_accuracy_rf:.4f}, F1 Score: {test_f1_rf:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ser_wav2vec import SpeechEmotionRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val = pd.concat([train_df, val_df], ignore_index=True)\n",
    "# save the df_train_val\n",
    "df_train_val.to_csv('df_train_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 20,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'checkpoint_dir': 'checkpoints',\n",
    "    'checkpoint': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ser = SpeechEmotionRecognition(\n",
    "    df=df_train_val,\n",
    "    model_name='facebook/wav2vec2-base',\n",
    "    batch_size=args['batch_size'],\n",
    "    lr=args['lr'],\n",
    "    num_epochs=args['epochs'],\n",
    "    checkpoint_dir=args['checkpoint_dir'],\n",
    "    gradient_accumulation_steps=args['gradient_accumulation_steps'],\n",
    "    checkpoint_path=args['checkpoint']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:57<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5015\n",
      "Checkpoint saved at checkpoints/model_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0209, Validation Accuracy: 0.6567\n",
      "Epoch 2/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8850\n",
      "Checkpoint saved at checkpoints/model_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8070, Validation Accuracy: 0.7205\n",
      "Epoch 3/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6303\n",
      "Checkpoint saved at checkpoints/model_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6323, Validation Accuracy: 0.7867\n",
      "Epoch 4/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4623\n",
      "Checkpoint saved at checkpoints/model_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6393, Validation Accuracy: 0.7912\n",
      "Epoch 5/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3920\n",
      "Checkpoint saved at checkpoints/model_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7181, Validation Accuracy: 0.7723\n",
      "Epoch 6/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:58<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3157\n",
      "Checkpoint saved at checkpoints/model_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6136, Validation Accuracy: 0.8216\n",
      "Epoch 7/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:58<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2933\n",
      "Checkpoint saved at checkpoints/model_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6619, Validation Accuracy: 0.8067\n",
      "Epoch 8/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2063\n",
      "Checkpoint saved at checkpoints/model_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6066, Validation Accuracy: 0.8186\n",
      "Epoch 9/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1536\n",
      "Checkpoint saved at checkpoints/model_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6812, Validation Accuracy: 0.8142\n",
      "Epoch 10/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1474\n",
      "Checkpoint saved at checkpoints/model_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:07<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8501, Validation Accuracy: 0.7877\n",
      "Epoch 11/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1191\n",
      "Checkpoint saved at checkpoints/model_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6991, Validation Accuracy: 0.8226\n",
      "Epoch 12/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1260\n",
      "Checkpoint saved at checkpoints/model_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6654, Validation Accuracy: 0.8201\n",
      "Epoch 13/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [02:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1095\n",
      "Checkpoint saved at checkpoints/model_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8650, Validation Accuracy: 0.7828\n",
      "Epoch 14/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0977\n",
      "Checkpoint saved at checkpoints/model_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7575, Validation Accuracy: 0.8211\n",
      "Epoch 15/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0833\n",
      "Checkpoint saved at checkpoints/model_epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7452, Validation Accuracy: 0.8236\n",
      "Epoch 16/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0959\n",
      "Checkpoint saved at checkpoints/model_epoch_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7283, Validation Accuracy: 0.8196\n",
      "Epoch 17/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1068\n",
      "Checkpoint saved at checkpoints/model_epoch_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7090, Validation Accuracy: 0.8191\n",
      "Epoch 18/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0798\n",
      "Checkpoint saved at checkpoints/model_epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8337, Validation Accuracy: 0.8201\n",
      "Epoch 19/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0685\n",
      "Checkpoint saved at checkpoints/model_epoch_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7212, Validation Accuracy: 0.8336\n",
      "Epoch 20/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 251/251 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0532\n",
      "Checkpoint saved at checkpoints/model_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 63/63 [00:08<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7962, Validation Accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ser.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint: checkpoints/model_epoch_19.pt\n"
     ]
    }
   ],
   "source": [
    "ser_best = SpeechEmotionRecognition(\n",
    "    df=df_train_val,\n",
    "    model_name='facebook/wav2vec2-base',\n",
    "    batch_size=args['batch_size'],\n",
    "    lr=args['lr'],\n",
    "    num_epochs=args['epochs'],\n",
    "    checkpoint_dir=args['checkpoint_dir'],\n",
    "    gradient_accumulation_steps=args['gradient_accumulation_steps'],\n",
    "    checkpoint_path='checkpoints/model_epoch_19.pt'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 56/56 [00:06<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8154, Test F1 Score: 0.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ser_best.evaluate_test_set(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "467final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
